# -*- coding: utf-8 -*-
"""SHL ASS PART 1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/149lRF-HqYp7DuiVUAYw6FoV7XwCtTZxH
"""

import pandas as pd
import string
import os

# Load dataset
df = pd.read_csv("/content/shl_assessment_dataset.csv")

# Step 1: Drop rows with missing values in essential fields
df = df.dropna(subset=[
    "Assessment Name",
    "Assessment Description",
    "Skills/Competencies",
    "Job Roles/Industries",
    "Tags/Categories"
])

# Step 2: Standardize text
def clean_text(text):
    if pd.isnull(text): return ""
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    text = ' '.join(text.split())
    return text

# Apply cleaning to all relevant columns
for col in [
    "Assessment Name",
    "Assessment Description",
    "Skills/Competencies",
    "Job Roles/Industries",
    "Tags/Categories"
]:
    df[col + "_Clean"] = df[col].apply(clean_text)

# Step 3: Remove duplicates
df = df.drop_duplicates(subset=["Assessment Name_Clean", "Assessment Description_Clean"])


os.makedirs("/mnt/data", exist_ok=True)

# Save cleaned dataset
df.to_csv("/mnt/data/shl_assessment_dataset_cleaned.csv", index=False)

df.to_csv("shl_assessment_dataset_cleaned.csv", index=False)

